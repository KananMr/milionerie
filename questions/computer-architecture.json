[
  {
    "question": "What is the primary characteristic of a Von Neumann architecture?",
    "options": ["Separate buses for instructions and data", "Shared memory and bus for both instructions and data", "Instructions are stored in ROM, data in RAM", "Multiple CPUs sharing a single memory"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "What is the primary advantage of a Harvard architecture?",
    "options": ["Lower cost due to shared components", "Simpler control unit design", "Ability to fetch instructions and data simultaneously due to separate buses", "Better support for virtual memory"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Which component of the CPU is responsible for performing arithmetic and logical operations?",
    "options": ["Control Unit (CU)", "Memory Management Unit (MMU)", "Arithmetic Logic Unit (ALU)", "Program Counter (PC)"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "What is the function of the Program Counter (PC) in a CPU?",
    "options": ["To store the result of the last arithmetic operation", "To hold the address of the next instruction to be executed", "To decode the current instruction", "To store the instruction currently being executed"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The Fetch-Decode-Execute cycle describes:",
    "options": ["The process of memory allocation", "The basic operation cycle of a CPU", "The sequence of I/O operations", "The steps in compiling a program"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Which type of bus is used to transfer data between the CPU and memory?",
    "options": ["Control Bus", "Address Bus", "Data Bus", "I/O Bus"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Which type of bus specifies the memory location for a read or write operation?",
    "options": ["Data Bus", "Address Bus", "Control Bus", "System Bus"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "RISC stands for:",
    "options": ["Rapid Instruction Set Computer", "Reduced Instruction Set Computer", "Relocatable Instruction Set Computer", "Register Intensive Set Computer"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "CISC stands for:",
    "options": ["Complex Instruction Set Computer", "Common Instruction Set Computer", "Compiled Instruction Set Computer", "Critical Instruction Set Computer"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A key characteristic of RISC architectures is:",
    "options": ["A large number of complex instructions", "Variable-length instruction formats", "A small number of simple, fixed-length instructions", "Most instructions access memory directly"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The clock speed of a CPU is typically measured in:",
    "options": ["Bytes per second (Bps)", "Floating Point Operations Per Second (FLOPS)", "Hertz (Hz) or Gigahertz (GHz)", "Meters per second (m/s)"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "CPI stands for:",
    "options": ["Cycles Per Instruction", "Cache Performance Index", "Central Processing Interface", "Computer Peripheral Interconnect"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Which register holds the instruction currently being executed?",
    "options": ["Program Counter (PC)", "Memory Address Register (MAR)", "Instruction Register (IR)", "Accumulator (ACC)"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Which register holds the address of the memory location to be accessed?",
    "options": ["Instruction Register (IR)", "Memory Data Register (MDR)", "Program Counter (PC)", "Memory Address Register (MAR)"],
    "answer": 3,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Which register holds data being transferred to or from memory?",
    "options": ["Memory Address Register (MAR)", "Program Counter (PC)", "Memory Data Register (MDR)", "Status Register"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Pipelining in a CPU is a technique used to:",
    "options": ["Increase the size of cache memory", "Improve performance by overlapping the execution of multiple instructions", "Reduce the power consumption of the CPU", "Simplify the control unit design"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A pipeline hazard that occurs when two or more instructions in the pipeline require the same resource is called a:",
    "options": ["Data Hazard", "Control Hazard", "Structural Hazard", "Execution Hazard"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A data hazard occurs when:",
    "options": ["A branch instruction changes the program flow", "An instruction depends on the result of a previous instruction that is still in the pipeline", "Two instructions try to use the same hardware unit simultaneously", "An I/O operation conflicts with a memory access"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A control hazard (or branch hazard) is caused by:",
    "options": ["The need to access memory for data", "Arithmetic overflow", "The presence of branch instructions that change the normal flow of execution", "Insufficient registers"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Which technique is used to handle data hazards by routing data from a later pipeline stage back to an earlier stage?",
    "options": ["Stalling", "Flushing the pipeline", "Branch prediction", "Forwarding (or Bypassing)"],
    "answer": 3,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Branch prediction is a technique used to mitigate:",
    "options": ["Structural hazards", "Data hazards", "Control hazards", "Power consumption issues"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A superscalar processor is one that:",
    "options": ["Has an extremely high clock speed", "Can execute multiple instructions simultaneously using multiple execution units", "Uses a very deep pipeline", "Has a very large cache"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The principle of locality refers to:",
    "options": ["Programs tending to use instructions and data near those recently used (temporal) or stored nearby (spatial)", "The physical location of the CPU on the motherboard", "The locality of I/O devices", "The speed of local memory access"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Cache memory is typically faster than main memory (RAM) because:",
    "options": ["It is larger in size", "It is made of DRAM chips", "It is made of SRAM chips and is physically closer to the CPU", "It uses a different bus architecture"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "In a direct-mapped cache, a memory block can be placed:",
    "options": ["In any cache line", "Only in one specific cache line determined by its address", "In any cache line within a specific set", "In a fully associative manner"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In a fully associative cache, a memory block can be placed:",
    "options": ["Only in one specific cache line", "In any available cache line", "In a specific set of cache lines", "Based on a hash function"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In an N-way set-associative cache, a memory block can be placed:",
    "options": ["In any cache line", "Only in one specific cache line", "In any of the N cache lines within one specific set", "Randomly across N sets"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The LRU (Least Recently Used) cache replacement policy means:",
    "options": ["The block that has been in the cache longest is replaced", "A randomly chosen block is replaced", "The block that has been accessed least recently is replaced", "The block that is used most frequently is replaced"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In a write-through cache policy:",
    "options": ["Data is written only to the cache, and main memory is updated when the block is replaced", "Data is written to both the cache and main memory simultaneously", "Data is written only to main memory, bypassing the cache", "Data is buffered before being written to cache and memory"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In a write-back cache policy:",
    "options": ["Data is written to both the cache and main memory simultaneously", "Data is written only to the cache, and main memory is updated only when the modified cache block is replaced", "Data is written only to main memory", "Data writes are always delayed"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Cache coherence ensures that:",
    "options": ["All caches in a multiprocessor system hold consistent (the same) data values for any given memory location", "The cache is always full", "Cache access times are uniform", "The cache replacement policy is optimal"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Virtual memory is a technique that:",
    "options": ["Makes the cache appear larger than it is", "Allows a system to use secondary storage (like a disk) as if it were part of main memory, enabling execution of programs larger than physical memory", "Creates virtual CPUs", "Speeds up memory access through virtualization"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "In a paged virtual memory system, memory is divided into fixed-size blocks called:",
    "options": ["Segments", "Frames (physical memory) and Pages (virtual memory)", "Blocks", "Sectors"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A page table is used to:",
    "options": ["Store the contents of pages", "Map virtual page numbers to physical frame numbers", "Keep track of page replacement policies", "Cache frequently accessed pages"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A Translation Lookaside Buffer (TLB) is a cache for:",
    "options": ["Frequently accessed data", "Recently used instructions", "Frequently used page table entries", "Disk sector addresses"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A page fault occurs when:",
    "options": ["A page in memory is corrupted", "The CPU tries to access a page that is not currently in physical memory", "The page table itself is not in memory", "A TLB miss occurs"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "DMA stands for:",
    "options": ["Dynamic Memory Allocation", "Direct Memory Access", "Data Management Array", "Distributed Memory Architecture"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Direct Memory Access (DMA) allows:",
    "options": ["The CPU to directly access I/O device registers", "I/O devices to transfer data directly to or from main memory without CPU intervention for each byte", "Memory to access I/O devices directly", "All memory accesses to bypass the cache"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Interrupt-driven I/O involves:",
    "options": ["The CPU continuously polling I/O devices", "The I/O device notifying the CPU when it is ready for data transfer or has completed an operation", "The CPU directly controlling data transfer for each byte", "Using DMA for all I/O operations"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Which category of Flynn's taxonomy describes a traditional single-processor Von Neumann machine?",
    "options": ["SISD (Single Instruction, Single Data)", "SIMD (Single Instruction, Multiple Data)", "MISD (Multiple Instruction, Single Data)", "MIMD (Multiple Instruction, Multiple Data)"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Which category of Flynn's taxonomy is often associated with vector processors or GPUs performing the same operation on large datasets?",
    "options": ["SISD", "SIMD", "MISD", "MIMD"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Multicore processors are an example of which Flynn's taxonomy category?",
    "options": ["SISD", "SIMD", "MISD", "MIMD"],
    "answer": 3,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In a shared memory multiprocessor system:",
    "options": ["Each processor has its own private memory, and communication occurs via message passing", "All processors share access to a common global memory space", "Memory is distributed among processors, but can be accessed globally", "Processors communicate only through I/O channels"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Symmetric Multiprocessing (SMP) refers to systems where:",
    "options": ["Processors have different roles and capabilities", "Multiple identical processors share a single main memory and are managed by one OS instance", "Each processor runs its own independent operating system", "Processing is done symmetrically across different geographical locations"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Amdahl's Law is used to predict:",
    "options": ["The reliability of a system", "The maximum speedup achievable by parallelizing a portion of a program", "The power consumption of a processor", "The cache hit rate"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The two's complement representation is commonly used for:",
    "options": ["Floating-point numbers", "Signed integers", "Unsigned integers", "Character encoding"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The IEEE 754 standard defines formats for:",
    "options": ["Integer arithmetic", "Character sets", "Floating-point number representation and arithmetic", "Network protocols"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "In immediate addressing mode, the operand is:",
    "options": ["Located in a register", "The address of the actual data", "Part of the instruction itself", "Found by adding an offset to a register"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "In direct addressing mode, the instruction contains:",
    "options": ["The operand itself", "The memory address where the operand is located", "A register number containing the operand", "A register number containing the address of the operand"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "In register addressing mode, the operand is:",
    "options": ["Stored in main memory", "Part of the instruction", "Located in a CPU register", "An offset value"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "MIPS (Millions of Instructions Per Second) is a measure of:",
    "options": ["Memory size", "Processor speed", "Disk access time", "Network bandwidth"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The control unit of a CPU is responsible for:",
    "options": ["Performing calculations", "Storing data temporarily", "Directing the operation of the processor by interpreting instructions and generating control signals", "Managing I/O devices"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'word' in computer architecture refers to:",
    "options": ["A sequence of 8 bits", "The natural unit of data used by a particular processor design (e.g., 32 bits or 64 bits)", "A command given to the CPU", "A type of memory"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Endianness refers to:",
    "options": ["The number of bits in a byte", "The order in which bytes of a multi-byte word are stored in memory (e.g., big-endian, little-endian)", "The type of error correction used in memory", "The speed of the system bus"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Little-endian means:",
    "options": ["The most significant byte is stored at the lowest memory address", "The least significant byte is stored at the lowest memory address", "Bytes are stored in reverse order of significance", "Data is always stored at the end of a memory block"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Big-endian means:",
    "options": ["The least significant byte is stored at the lowest memory address", "The most significant byte is stored at the lowest memory address", "Data is always stored at the beginning of a memory block", "Bytes are stored in increasing order of significance"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "An interrupt is:",
    "options": ["A hardware or software signal to the processor indicating an event that needs immediate attention", "A pause in program execution requested by the user", "An error in the program's logic", "A type of memory refresh cycle"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "An Interrupt Vector Table (IVT) contains:",
    "options": ["A list of all interrupt requests", "The addresses of interrupt service routines (ISRs) for various interrupt types", "Data related to pending interrupts", "The status of all I/O devices"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Which of the following is a type of ROM (Read-Only Memory)?",
    "options": ["DRAM", "SRAM", "EEPROM (Electrically Erasable Programmable Read-Only Memory)", "Cache"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "DRAM (Dynamic Random-Access Memory) requires:",
    "options": ["Constant power to retain data, even when not being accessed", "Periodic refreshing to maintain its data", "UV light to erase its contents", "Magnetic fields for storage"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "SRAM (Static Random-Access Memory) is generally:",
    "options": ["Slower and cheaper than DRAM", "Faster and more expensive than DRAM, and does not require refreshing", "Used for main memory due to its high density", "A type of non-volatile memory"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The memory hierarchy is organized based on:",
    "options": ["Physical size of memory components", "Cost per bit only", "Speed, cost, and capacity, with faster, smaller, more expensive memory closer to the CPU", "The manufacturer of the memory chips"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A cache 'hit' occurs when:",
    "options": ["The cache is full and a block needs to be replaced", "The requested data is found in the cache", "The requested data is not found in the cache", "An error occurs during cache access"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A cache 'miss' occurs when:",
    "options": ["The requested data is found in the cache", "The cache is being written to", "The requested data is not found in the cache and must be fetched from a lower level of memory", "The cache is empty"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The 'hit rate' of a cache is:",
    "options": ["The number of cache misses per second", "The fraction of memory accesses that are found in the cache", "The speed at which data can be retrieved from the cache", "The size of the cache divided by the size of main memory"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'dirty bit' in a cache line is used in conjunction with which write policy?",
    "options": ["Write-through", "Write-around", "Write-back", "No-write allocate"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "What does a dirty bit indicate?",
    "options": ["The cache line contains invalid data", "The cache line has been modified and its contents are different from main memory", "The cache line is scheduled for replacement", "The cache line has been accessed recently"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Temporal locality suggests that:",
    "options": ["If a memory location is accessed, nearby locations are likely to be accessed soon", "If a memory location is accessed, it is likely to be accessed again soon", "Memory accesses are temporary and short-lived", "Data is stored locally in time"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Spatial locality suggests that:",
    "options": ["If a memory location is accessed, it is likely to be accessed again soon", "Memory is organized in a 3D space", "If a memory location is accessed, memory locations physically near it are likely to be accessed soon", "Accesses to memory are sparse"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The Memory Management Unit (MMU) is responsible for:",
    "options": ["Managing cache coherence", "Translating virtual addresses to physical addresses", "Performing arithmetic operations on memory addresses", "Controlling DMA transfers"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Segmentation is a virtual memory technique where memory is divided into:",
    "options": ["Fixed-size pages", "Variable-size segments, often corresponding to logical program units (e.g., code, data, stack)", "Cache lines", "Disk blocks"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "What is the typical role of the system bus?",
    "options": ["To connect only the CPU and cache", "To provide a communication pathway connecting major computer components like CPU, memory, and I/O devices", "To power the computer components", "To cool the CPU"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A microprogram is:",
    "options": ["A very small user program", "A sequence of microinstructions stored in control memory that implements a machine instruction", "A program for microcontrollers", "A program that analyzes micro-operations"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A hardwired control unit:",
    "options": ["Uses a microprogram to generate control signals", "Generates control signals directly from the instruction bits using fixed logic circuits (gates, flip-flops)", "Is slower than a microprogrammed control unit", "Is more flexible and easier to modify than a microprogrammed control unit"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "VLIW stands for:",
    "options": ["Very Large Instruction Word", "Variable Length Instruction Width", "Virtual Local Instruction Window", "Vector Logic Instruction Workload"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In a VLIW architecture, instruction scheduling (finding parallelism) is primarily done by:",
    "options": ["The hardware at runtime", "The operating system", "The compiler at compile time", "The user programmer"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Out-of-order execution allows a processor to:",
    "options": ["Execute instructions in the order they appear in the program only", "Execute instructions in a different order than specified by the program, as long as data dependencies are respected, to improve performance by utilizing idle execution units", "Reorder memory accesses arbitrarily", "Execute only a subset of instructions out of order"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A Reorder Buffer (ROB) is often used in conjunction with:",
    "options": ["Direct-mapped caches", "Out-of-order execution, to ensure instructions commit in program order", "Virtual memory management", "DMA controllers"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Speculative execution is a technique where:",
    "options": ["The processor speculates on the outcome of user input", "The processor makes a guess (e.g., about a branch outcome or data dependency) and starts executing instructions along the guessed path before the outcome is known, to improve performance", "Only a specific set of instructions are executed", "Execution is based on statistical speculation of program behavior"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A Branch Target Buffer (BTB) is used to:",
    "options": ["Buffer data for branch instructions", "Store the target addresses of recently executed branch instructions to speed up fetching of the target instruction if the branch is taken again", "Predict whether a branch will be taken or not taken", "Temporarily store branch instructions"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Hardware multithreading (e.g., SMT - Simultaneous Multithreading) allows:",
    "options": ["A single CPU core to execute multiple threads by switching between them very rapidly", "Multiple CPU cores to share a single thread", "A single CPU core to appear as multiple logical processors to the OS by having hardware support for multiple thread contexts and sharing execution units among them", "Threads to be executed directly on hardware without an OS"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The MESI protocol is a type of:",
    "options": ["Cache replacement policy", "Cache coherence protocol", "Branch prediction algorithm", "Virtual memory management scheme"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "In the MESI protocol, 'M' stands for:",
    "options": ["Memory", "Modified", "Miss", "Mapped"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "In the MESI protocol, 'E' stands for:",
    "options": ["Empty", "Error", "Exclusive", "Execute"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "In the MESI protocol, 'S' stands for:",
    "options": ["Static", "Shared", "System", "Synchronized"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "In the MESI protocol, 'I' stands for:",
    "options": ["Instruction", "Immediate", "Invalid", "Interconnect"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "An interconnection network in a multiprocessor system is used for:",
    "options": ["Connecting the system to the internet", "Communication between processors, and between processors and memory modules", "Connecting peripheral devices only", "Power distribution"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A crossbar switch is a type of:",
    "options": ["Cache memory", "Interconnection network that allows simultaneous connections between multiple inputs and outputs", "CPU register", "Power supply unit"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A system call is:",
    "options": ["A call between different systems on a network", "A programmatic way in which a computer program requests a service from the kernel of the operating system", "A hardware signal for system reset", "A call to a system library function that runs in user mode"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Memory protection is a mechanism to:",
    "options": ["Protect memory chips from physical damage", "Prevent a process from accessing memory that has not been allocated to it, or to which it does not have access rights", "Encrypt all data stored in memory", "Protect memory from power surges"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "RAID (Redundant Array of Independent Disks) Level 0 (striping) provides:",
    "options": ["High redundancy and fault tolerance", "Improved performance by spreading data across multiple disks, but no redundancy", "Mirroring of data for backup", "Parity checking for error correction"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "RAID Level 1 (mirroring) provides:",
    "options": ["Increased storage capacity by combining disks", "Improved read performance and data redundancy by writing identical data to two or more disks", "Striping with parity", "Distributed parity"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "RAID Level 5 (striping with distributed parity) provides:",
    "options": ["Only performance improvement", "Data redundancy and improved read performance, with parity information distributed across all disks", "Only mirroring", "No fault tolerance"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The term 'ISA' in computer architecture usually refers to:",
    "options": ["Industry Standard Architecture (a bus type)", "Instruction Set Architecture", "Internal System Address", "Integrated Storage Array"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "An opcode (operation code) in an instruction specifies:",
    "options": ["The address of the operand", "The operation to be performed (e.g., add, subtract, load)", "The size of the operand", "The location of the next instruction"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Polling I/O involves:",
    "options": ["The CPU periodically checking the status of an I/O device to see if it's ready for an operation", "The I/O device sending an interrupt to the CPU", "Using DMA for all I/O transfers", "The operating system managing I/O requests"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'context switch' in an operating system involves:",
    "options": ["Switching the CPU's power context", "Saving the state of the currently running process (or thread) and loading the saved state of another process (or thread) to allow multitasking", "Changing the display context (e.g., resolution)", "Switching between different programming language contexts"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Which component is often referred to as the 'brain' of the computer?",
    "options": ["Main Memory (RAM)", "Hard Disk Drive (HDD)", "Central Processing Unit (CPU)", "Motherboard"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The ASCII character encoding standard typically uses how many bits per character?",
    "options": ["16 bits", "32 bits", "7 or 8 bits", "4 bits"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Unicode is a character encoding standard designed to:",
    "options": ["Encode only English characters", "Support characters from most of the world's writing systems", "Compress text data efficiently", "Be used only for web pages"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'bus master' is a device that can:",
    "options": ["Only receive data from the bus", "Initiate data transfers on the bus", "Control the speed of the bus", "Terminate the bus signals"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Which of these is a form of non-volatile memory?",
    "options": ["DRAM", "SRAM", "Cache Memory", "Flash Memory (e.g., SSDs, USB drives)"],
    "answer": 3,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "In a typical five-stage pipeline (IF, ID, EX, MEM, WB), 'WB' stands for:",
    "options": ["Wait Buffer", "Write Bus", "Write Back", "Word Boundary"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "In a typical five-stage pipeline, the 'ID' stage usually involves:",
    "options": ["Instruction Fetch", "Instruction Decode and Register Fetch", "Execute operation", "Memory access"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'stack pointer' register is typically used to:",
    "options": ["Point to the current instruction", "Point to the top of the runtime stack in memory", "Store the base address of the stack", "Indicate stack overflow"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The 'stack' in computer memory is often used for:",
    "options": ["Storing large data files", "Managing function calls (storing return addresses, local variables, parameters)", "Caching frequently accessed instructions", "Permanent program storage"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'heap' in computer memory is typically used for:",
    "options": ["Storing function call information", "Dynamic memory allocation (e.g., using `malloc` in C or `new` in C++)", "Storing global variables only", "CPU register storage"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Prefetching is a technique used to:",
    "options": ["Predict branch outcomes", "Fetch instructions or data into cache or buffers before they are actually needed, based on predicted access patterns", "Delay fetching of instructions to save power", "Fetch only the first part of an instruction"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A barrel shifter is a digital circuit that can:",
    "options": ["Shift or rotate a data word by a specified number of bits in a single clock cycle", "Store shifted data temporarily", "Count the number of shifts performed", "Perform arithmetic shifts only"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The concept of 'locality of reference' is fundamental to the effectiveness of:",
    "options": ["DMA controllers", "Cache memory and virtual memory", "Interrupt handling", "Arithmetic Logic Units"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Which component typically connects the Northbridge (if present) to high-speed devices like RAM and graphics cards?",
    "options": ["Southbridge", "System Bus / Front Side Bus (older terminology)", "PCI Bus", "USB Bus"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The Southbridge chipset (in older architectures) typically handles:",
    "options": ["CPU to RAM communication", "Slower I/O devices like USB, audio, SATA, PCI bus", "Graphics card interface", "Cache management"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In modern CPU architectures, functions previously handled by the Northbridge (like memory controller, PCIe for graphics) are often integrated into:",
    "options": ["The Southbridge (now called PCH)", "The CPU itself", "The operating system", "External dedicated chips"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'write buffer' can be used with a write-through cache to:",
    "options": ["Store data that will be written back later", "Reduce CPU stalls by allowing the CPU to continue execution while writes to main memory are in progress", "Buffer read requests to memory", "Increase the size of the cache"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'victim cache' is a small, fully associative cache used to:",
    "options": ["Store victims of cyber attacks", "Store blocks that have been recently evicted from a lower-level cache (e.g., L1), giving them a second chance before going to main memory", "Cache information about page faults", "Store data that is rarely used"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The term 'NUMA' stands for:",
    "options": ["No Uniform Memory Access", "Non-Uniform Memory Access", "New Universal Memory Architecture", "Numeric Unified Memory Array"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "In a NUMA architecture:",
    "options": ["All processors have equal access time to all memory locations", "Memory access time depends on the memory location relative to a processor; accessing local memory is faster than accessing remote memory (memory associated with another processor)", "Memory is not accessible by all processors", "There is no main memory; only caches are used"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The 'critical word first' technique in cache memory means:",
    "options": ["Only critical data is stored in the cache", "When a cache miss occurs and a block is fetched from main memory, the specific word requested by the CPU is sent first to the CPU, while the rest of the block is filled into the cache, to reduce stall time.", "The first word of a cache block is always considered critical", "Words are stored in cache in order of criticality"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'branch delay slot' is a feature in some pipelined RISC architectures where:",
    "options": ["Branch instructions are always delayed by one cycle", "The instruction immediately following a branch instruction is always executed, regardless of whether the branch is taken or not, to keep the pipeline busy", "The branch target address is delayed", "The pipeline slot for branch instructions is larger"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The 'bandwidth' of a memory system refers to:",
    "options": ["The access time for a single word", "The rate at which data can be transferred to or from memory (e.g., in bytes per second)", "The total storage capacity of the memory", "The width of the memory address bus"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The 'latency' of a memory system refers to:",
    "options": ["The rate of data transfer", "The total time taken from the start of a memory access request until the data is available or the access is complete", "The storage capacity per unit cost", "The physical width of the memory module"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'Level 1 Cache' (L1 Cache) is typically:",
    "options": ["Larger and slower than L2 cache", "Smaller, faster, and closer to the CPU core than L2 cache", "Located off-chip", "Shared by all cores in a multicore processor"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "In indexed addressing mode, the effective address is calculated by:",
    "options": ["Using the instruction's address field directly", "Adding the contents of an index register to a base address (often part of the instruction)", "Using the contents of a register as the address", "The address is part of the instruction"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The concept of 'cycle stealing' is associated with:",
    "options": ["Cache replacement policies", "Branch prediction", "DMA operations, where the DMA controller temporarily takes control of the bus from the CPU to transfer data", "Virtual memory page swaps"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "An 'Assembler' is a program that translates:",
    "options": ["High-level language code to machine code", "Assembly language code to machine code", "Machine code to assembly language code (disassembler)", "Source code to intermediate code"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'Linker' is a program that:",
    "options": ["Translates source code to object code", "Combines one or more object files (produced by a compiler/assembler) and library routines into a single executable program, resolving external references", "Loads an executable program into memory for execution", "Debugs compiled programs"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'Loader' is a part of the operating system responsible for:",
    "options": ["Linking object files", "Loading an executable program from disk into main memory and preparing it for execution", "Compiling source code", "Managing user accounts"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The term 'granularity' in the context of parallel processing or memory access refers to:",
    "options": ["The speed of individual operations", "The size of the data items or tasks being processed or accessed (e.g., fine-grained vs. coarse-grained)", "The type of material used in processor manufacturing", "The number of cores in a processor"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "What is the primary purpose of status flags (e.g., Zero, Carry, Overflow, Negative) in a CPU's status register?",
    "options": ["To indicate the current CPU temperature", "To store the status of the most recent arithmetic or logical operation, which can then be used for conditional branching", "To show the status of I/O devices", "To indicate the current user privilege level"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'trap' or 'software interrupt' is typically caused by:",
    "options": ["A hardware failure", "An exceptional condition detected by the hardware (e.g., division by zero) or a specific instruction in the program (e.g., a system call)", "An external device signaling the CPU", "A power outage"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The 'bootstrap loader' or 'bootloader' is a program that:",
    "options": ["Loads user applications after the OS is running", "Is stored in ROM and runs when the computer is powered on, responsible for initializing hardware and loading the operating system kernel into memory", "Manages network boot processes", "A tool for creating bootable USB drives"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Which of these is a common interface for connecting storage devices like HDDs and SSDs to the motherboard?",
    "options": ["Ethernet", "HDMI", "SATA (Serial ATA) or NVMe (for some SSDs)", "USB (though external drives use this, internal primary interface is often SATA/NVMe)"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The PCI Express (PCIe) bus is commonly used for connecting:",
    "options": ["Low-speed peripherals like keyboards and mice", "High-speed components like graphics cards, SSDs, and network cards to the motherboard", "Only CPU to main memory", "External storage devices exclusively"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'device driver' is a piece of software that:",
    "options": ["Physically drives a mechanical part of a device", "Allows the operating system and higher-level software to communicate with and control a specific hardware device", "Is embedded in the hardware device itself", "A tool for users to configure devices"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'bit' is the basic unit of information in computing and can represent:",
    "options": ["A decimal digit (0-9)", "One of two values, typically 0 or 1", "An alphabetic character", "A memory address"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'byte' is typically composed of how many bits?",
    "options": ["4 bits", "16 bits", "8 bits", "32 bits"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "In pipelining, 'latency' refers to:",
    "options": ["The number of instructions executed per unit time", "The total time it takes for a single instruction to complete its passage through all stages of the pipeline", "The number of pipeline stages", "The clock cycle time"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In pipelining, 'throughput' refers to:",
    "options": ["The time for one instruction to exit the pipeline", "The rate at which instructions are completed and exit the pipeline (ideally one per clock cycle in a balanced pipeline)", "The depth of the pipeline", "The delay caused by hazards"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'decoder' circuit in a CPU's control unit is used to:",
    "options": ["Encrypt instructions", "Interpret the opcode of an instruction and generate control signals for other CPU components", "Decode data from memory", "Convert analog signals to digital"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The concept of 'idempotence' in I/O operations means:",
    "options": ["The operation is very fast", "Performing the operation multiple times has the same effect as performing it once", "The operation requires user identification", "The operation can only be performed by the CPU"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "What is a 'buffer' in the context of I/O or data transfer?",
    "options": ["A tool for polishing data", "A temporary storage area in memory used to hold data while it is being transferred between devices or processes that operate at different speeds or in bursts", "A type of CPU register", "A logical operator"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'checksum' is often used for:",
    "options": ["Calculating the sum of numbers in a program", "Error detection in data transmission or storage, by calculating a small, fixed-size numerical value based on the data content", "Encrypting data", "Compressing data"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The 'endianness' of a system can be a concern when:",
    "options": ["Calculating floating-point numbers", "Transferring binary data (e.g., multi-byte integers) between systems with different endianness conventions", "Performing string comparisons", "Accessing I/O devices"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'stack overflow' error typically occurs when:",
    "options": ["The heap memory is exhausted", "The runtime stack grows beyond its allocated memory limit, often due to excessive nested function calls or very deep recursion", "A stack pointer register fails", "Data overflows from one stack to another"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Which addressing mode would be most suitable for accessing elements of an array if the base address of the array is in a register?",
    "options": ["Immediate addressing", "Direct addressing", "Register indirect addressing with displacement (or Indexed addressing)", "Register addressing"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "What is the primary function of an I/O controller (or device controller)?",
    "options": ["To perform arithmetic operations for I/O devices", "To manage the interface between an I/O device and the system bus/CPU, translating commands and data", "To store data for I/O devices", "To power I/O devices"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In a memory-mapped I/O system:",
    "options": ["I/O devices have a separate address space from memory", "I/O device registers are mapped into the system's memory address space, and can be accessed using the same instructions as memory locations", "All I/O operations are mapped to disk", "Memory is mapped directly to I/O device buffers"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In a port-mapped I/O (or isolated I/O) system:",
    "options": ["I/O devices share the same address space as memory", "I/O devices have a separate address space from memory, and special I/O instructions (e.g., IN, OUT) are used to access them", "All I/O ports are mapped to network addresses", "Memory ports are used for I/O operations"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'process' in an operating system context is:",
    "options": ["A sequence of CPU instructions", "A program in execution, including its current state, memory space, and system resources", "A hardware component", "A data file"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'thread' in an operating system context is:",
    "options": ["Synonymous with a process", "The basic unit of CPU utilization within a process; multiple threads can exist within a single process, sharing its resources but having their own execution stack and program counter", "A physical connection between CPU cores", "A type of system bus"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A GPU (Graphics Processing Unit) is a specialized electronic circuit designed to:",
    "options": ["Manage general-purpose operating system tasks", "Rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device; also used for general-purpose parallel computation (GPGPU)", "Control network traffic", "Store graphical assets permanently"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "What is 'Moore's Law' (historical observation)?",
    "options": ["The observation that CPU clock speeds double approximately every two years", "The observation that the number of transistors on a microchip doubles approximately every two years, while the cost remains constant or decreases", "A law governing memory access times", "A prediction about the growth of internet bandwidth"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Instruction-Level Parallelism (ILP) refers to:",
    "options": ["Running multiple independent programs in parallel", "The ability of a processor to execute multiple instructions from a single program thread simultaneously (e.g., through pipelining, superscalar execution, out-of-order execution)", "Parallelism achieved by using multiple CPU cores", "Parallel processing of I/O instructions"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Data-Level Parallelism (DLP) refers to:",
    "options": ["Parallel processing of different data types", "Performing the same operation simultaneously on multiple data elements, often found in SIMD architectures or vector processing", "Parallel access to different levels of the memory hierarchy", "Achieving parallelism by distributing data across multiple disks"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Task-Level Parallelism (TLP) or Thread-Level Parallelism refers to:",
    "options": ["Parallel execution of individual CPU instructions", "Executing different threads or tasks (which may be part of the same program or different programs) concurrently, often utilizing multiple CPU cores", "Parallelizing I/O tasks", "A technique for managing task priorities"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'deadlock' in a concurrent system occurs when:",
    "options": ["A thread encounters a fatal error", "Two or more threads are blocked indefinitely, each waiting for a resource held by another thread in the set", "The system runs out of memory", "A hardware component fails"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'semaphore' is a synchronization primitive that can be used to:",
    "options": ["Send signals between processes on different machines", "Control access by multiple processes/threads to a common resource in a concurrent system, by maintaining a counter of available resources", "Encrypt data for secure transmission", "Store temporary data for threads"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'mutex' (mutual exclusion lock) is a synchronization primitive that:",
    "options": ["Allows multiple threads to access a shared resource simultaneously", "Ensures that only one thread can access a particular shared resource or execute a critical section of code at any given time", "Counts the number of threads accessing a resource", "Mutes audio output from a thread"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The 'kernel mode' (or supervisor mode) of a CPU typically grants:",
    "options": ["Restricted access to hardware and memory, intended for user applications", "Full, unrestricted access to all hardware and memory, intended for the operating system kernel", "Access only to I/O devices", "A power-saving mode for the CPU"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The 'user mode' of a CPU typically grants:",
    "options": ["Full access to all hardware", "Restricted access to hardware and memory, with privileged operations requiring a transition to kernel mode (e.g., via a system call)", "Access only to user interface elements", "The default mode for the operating system kernel"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'hypervisor' is software that:",
    "options": ["Supervises network traffic", "Creates and runs virtual machines (VMs), allowing multiple operating systems to run concurrently on a single physical host", "Manages hyperlinks on web pages", "A tool for hyper-threading optimization"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Full virtualization typically requires:",
    "options": ["No special hardware support", "Hardware assistance from the CPU (e.g., Intel VT-x, AMD-V) to efficiently run guest operating systems without modification", "A specific type of operating system", "Only software emulation"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Paravirtualization involves:",
    "options": ["Running guest OSs directly on hardware without a hypervisor", "Modifying the guest operating system's kernel to be aware that it is running in a virtualized environment and to cooperate with the hypervisor, potentially improving performance", "Virtualizing only a part of the hardware", "A paradox in virtualization techniques"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "What is 'checkpointing' in the context of fault tolerance or long computations?",
    "options": ["Marking specific points in source code for debugging", "Periodically saving the state of a running process or system so that it can be restarted from that point in case of a failure, avoiding loss of all computation", "A security checkpoint for accessing system resources", "A technique for optimizing database checkpoints"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'watchdog timer' is a hardware or software timer used to:",
    "options": ["Time how long a user watches a screen", "Detect and recover from computer malfunctions. If the timer is not reset by the system within a certain interval (indicating normal operation), it triggers a corrective action like a system reset.", "Schedule tasks at regular intervals", "Measure the performance of a timer circuit"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "In computer networking, 'packet switching' involves:",
    "options": ["Switching physical network cables for each packet", "Breaking down a message into smaller units called packets, which are then routed independently through the network and reassembled at the destination", "Using dedicated circuits for each communication session", "Switching between different network protocols for each packet"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "In computer networking, 'circuit switching' involves:",
    "options": ["Breaking messages into packets", "Establishing a dedicated communication path (circuit) between two endpoints for the duration of their communication session, like a traditional telephone call", "Switching network circuits on and off rapidly", "Using virtual circuits for all data transfer"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'firewall' in computer security is a network security system that:",
    "options": ["Protects against physical fires in data centers", "Monitors and controls incoming and outgoing network traffic based on predetermined security rules, acting as a barrier between a trusted internal network and untrusted external networks", "A software for managing file access permissions", "A hardware device for cooling network equipment"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "What is 'Instruction Pipelining Depth'?",
    "options": ["The number of instructions that can be stored in the instruction cache", "The number of stages in the CPU's instruction pipeline", "The depth of the call stack for instructions", "The maximum number of instructions a program can have"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Increasing pipeline depth can potentially increase throughput but may also increase:",
    "options": ["Cache size", "The penalty (stall cycles) from hazards like mispredicted branches", "Instruction complexity", "Power consumption significantly for each stage"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'write allocate' cache policy means that on a write miss:",
    "options": ["The write operation is performed directly in main memory, bypassing the cache", "The block containing the write location is first fetched from main memory into the cache, and then the write operation is performed in the cache", "Memory is allocated for the write operation in a buffer", "The cache allocates space only for read operations"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'no-write allocate' (or write-around) cache policy means that on a write miss:",
    "options": ["The block is fetched into the cache, then written", "The write operation is performed directly in main memory, and the cache is not modified (the block is not loaded into cache on a write miss)", "No write operations are allowed to the cache", "The cache allocates space but doesn't write immediately"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The 'Principle of Optimal Caching' (Belady's Algorithm) states that the ideal replacement policy would be to replace:",
    "options": ["The least recently used block", "The most recently used block", "The block that will not be used for the longest time in the future (this is optimal but not practically implementable as it requires future knowledge)", "A random block"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'unified cache' is a cache that stores:",
    "options": ["Only instructions", "Only data", "Both instructions and data in the same cache", "Cache entries from multiple CPUs"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'split cache' system typically has:",
    "options": ["A single cache for both instructions and data", "Separate caches for instructions (I-cache) and data (D-cache), often at the L1 level", "A cache that is split into multiple physical modules", "A cache that can be dynamically partitioned"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The term 'thrashing' in a virtual memory system refers to a situation where:",
    "options": ["The CPU is executing instructions very rapidly", "The system spends an excessive amount of time swapping pages between main memory and disk, due to frequent page faults, leading to poor performance", "The disk drive is making loud thrashing noises", "Memory is being thrashed by error correction codes"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'working set' of a process refers to:",
    "options": ["The set of all I/O devices it is currently using", "The set of pages that the process is actively using or has recently used; keeping the working set in main memory can help reduce page faults", "The set of CPU registers used by the process", "The tasks assigned to the process by the operating system"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "In the context of interconnection networks, 'topology' refers to:",
    "options": ["The geographical layout of the network", "The physical or logical arrangement of nodes (e.g., processors, memory modules) and the links connecting them (e.g., bus, ring, mesh, hypercube)", "The type of protocols used on the network", "The speed of the network links"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'bus arbitration' mechanism is needed when:",
    "options": ["Multiple devices want to use the bus simultaneously, to decide which device gets control of the bus", "The bus speed needs to be arbitrated", "Data on the bus is corrupted", "The bus needs to be physically reconfigured"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "Daisy chaining is a method of:",
    "options": ["Connecting memory modules", "Bus arbitration or interrupt priority handling where devices are connected in series, and the grant/acknowledge signal propagates through the chain", "Linking multiple CPUs together", "Encrypting data chains"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Error Correcting Codes (ECC) memory is capable of:",
    "options": ["Only detecting memory errors", "Detecting and correcting certain types of memory errors (e.g., single-bit errors)", "Preventing all memory errors from occurring", "Increasing memory speed"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'parity bit' is often used for:",
    "options": ["Encrypting data", "Simple error detection in data transmission or storage, by ensuring the total number of 1-bits in a set (including the parity bit) is always even or always odd", "Correcting multi-bit errors", "Increasing data storage capacity"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'carry lookahead adder' is a type of adder circuit that:",
    "options": ["Adds numbers by looking ahead at future inputs", "Speeds up addition by calculating carry signals in advance, rather than waiting for them to propagate through each bit stage, reducing delay compared to a ripple-carry adder", "Looks for carry bits to correct errors", "A very slow but simple adder design"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'multiplexer' (MUX) is a digital circuit that:",
    "options": ["Multiplies two binary numbers", "Selects one of several input signals and forwards the selected input to a single output line, based on control select signals", "Demultiplexes a single input to multiple outputs", "Adds multiple input signals together"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'demultiplexer' (DEMUX) is a digital circuit that:",
    "options": ["Selects one of many inputs to a single output", "Takes a single input signal and routes it to one of several output lines, based on control select signals", "Multiplexes multiple output signals", "Performs division on multiple inputs"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'flip-flop' is a basic bistable electronic circuit that:",
    "options": ["Generates clock pulses", "Can store one bit of information and has two stable states", "Performs logical operations like AND/OR", "Amplifies signals"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "The 'firmware' of a hardware device is:",
    "options": ["The physical casing of the device", "Software that is permanently or semi-permanently programmed into a hardware device's read-only memory (ROM) or flash memory, providing low-level control for the device", "A type of flexible hardware component", "Software that is frequently updated by the user"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Power consumption is a critical design constraint in modern processors, especially for mobile and embedded devices. True or False?",
    "options": ["True", "False", "Only for desktop CPUs", "Only for GPUs"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Dynamic power consumption in CMOS circuits is primarily proportional to:",
    "options": ["Static leakage current", "The operating voltage squared, capacitance, and switching frequency (P ~ CV²f)", "The number of transistors only", "The physical size of the chip"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Static power consumption (leakage power) in CMOS circuits is primarily due to:",
    "options": ["Switching activity of transistors", "Current that flows even when transistors are ideally off, which becomes more significant with smaller transistor sizes and lower threshold voltages", "Power used by the clock distribution network", "Heat generated by the chip"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Techniques like 'clock gating' and 'power gating' are used to:",
    "options": ["Increase clock speed", "Reduce dynamic and static power consumption by turning off the clock or power supply to idle parts of the chip", "Synchronize multiple clocks", "Protect against power surges"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The 'ISA level' is considered the boundary between:",
    "options": ["Hardware and operating system", "Software (seen by the programmer/compiler) and the underlying hardware implementation", "Application software and system software", "User mode and kernel mode"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'Load-Store Architecture' (common in RISC) means that:",
    "options": ["All instructions can access memory operands directly", "Only explicit load and store instructions are used to access memory; arithmetic/logical operations are performed on operands in registers", "The architecture is optimized for loading and storing programs", "Memory access is handled by a separate co-processor"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'General Purpose Register' (GPR) in a CPU is used to:",
    "options": ["Store the program counter", "Hold data or addresses temporarily for manipulation by the ALU and other CPU units; they are not dedicated to a single function", "Store status flags", "Cache instructions"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'Floating Point Unit' (FPU) is a part of a CPU specialized for:",
    "options": ["Integer arithmetic", "Performing arithmetic operations on floating-point numbers", "Managing memory for floating data", "Controlling floating I/O devices"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "A 'System on a Chip' (SoC) typically integrates:",
    "options": ["Only the CPU core", "Multiple components like CPU, GPU, memory controllers, I/O interfaces, and other peripherals onto a single integrated circuit chip", "Only memory and storage", "Software for an entire system"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The 'address space' of a processor refers to:",
    "options": ["The physical space occupied by the processor", "The total range of memory addresses that the processor can access", "The space used for storing addresses in the cache", "The address of the processor on the network"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "If a processor has an N-bit address bus, it can address up to how many unique memory locations?",
    "options": ["N locations", "2*N locations", "2^N locations", "N^2 locations"],
    "answer": 2,
    "category": "Computer Architecture",
    "difficulty": 1
  },
  {
    "question": "Memory interleaving is a technique used to:",
    "options": ["Increase memory capacity", "Improve memory bandwidth by dividing memory into multiple banks that can be accessed in parallel or in an overlapping manner", "Reduce memory latency for single accesses", "Protect memory from unauthorized access"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'pipeline bubble' or 'stall' is:",
    "options": ["A hardware component for managing pipeline flow", "A delay in the pipeline execution, often inserted to resolve a hazard, where one or more pipeline stages do no useful work for a cycle", "An error in the pipeline logic", "A way to speed up pipeline execution"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'write conflict' or 'Write-After-Write (WAW)' hazard occurs when:",
    "options": ["An instruction tries to read a value before a previous instruction writes it", "Two different instructions try to write to the same location, and the writes occur out of program order, potentially leading to the wrong value being stored", "An instruction tries to write a value before a previous instruction reads it", "A write operation conflicts with a read operation to a different location"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'Read-After-Write (RAW)' hazard is also known as a:",
    "options": ["True data dependency", "Anti-dependency", "Output dependency", "Control dependency"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'Write-After-Read (WAR)' hazard is also known as a:",
    "options": ["True data dependency", "Anti-dependency", "Output dependency", "Structural dependency"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Tomasulo's algorithm is a hardware algorithm for dynamic instruction scheduling that allows:",
    "options": ["Static scheduling by the compiler", "Out-of-order execution by using reservation stations and a common data bus (CDB) to resolve data dependencies and distribute results", "In-order execution with deep pipelining", "Efficient branch prediction"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'Reservation Station' in Tomasulo's algorithm is used to:",
    "options": ["Store branch target addresses", "Hold instructions that have been issued but are waiting for their operands to become available or for an execution unit to be free", "Buffer memory write operations", "Reserve cache lines for future use"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The Common Data Bus (CDB) in Tomasulo's algorithm is used to:",
    "options": ["Transfer data between CPU and main memory", "Broadcast results from execution units to reservation stations and registers that are waiting for those results", "Connect I/O devices to the CPU", "Synchronize multiple CPU cores"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'trace cache' is a type of instruction cache that stores:",
    "options": ["Only data traces", "Sequences of dynamically executed instructions (traces), including non-contiguous instructions from taken branches, to improve instruction fetch bandwidth and overcome branch penalties", "Traces of cache misses", "Debugging trace information"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The term 'Dennard scaling' (historically) observed that as transistors get smaller:",
    "options": ["Their power density remains constant (power use scales down with area), allowing clock speeds and transistor counts to increase without significantly increasing overall power consumption of the chip. This scaling has largely broken down.", "Their power consumption increases proportionally", "Their speed decreases", "They become less reliable"],
    "answer": 0,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "What is 'dark silicon'?",
    "options": ["Silicon wafers that have not been processed", "A phenomenon where, due to power density limitations (breakdown of Dennard scaling), not all transistors or cores on a chip can be powered on and operated at full speed simultaneously; some parts must remain 'dark' (powered down or throttled) to stay within thermal limits.", "Silicon used for optical components", "A type of highly reflective silicon"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'Network on Chip' (NoC) is an approach to:",
    "options": ["Connecting computers in a local area network", "Designing the communication subsystem on an integrated circuit (chip), typically for connecting multiple cores, caches, and other IP blocks, using packet-switched networking principles", "Implementing network protocols in hardware", "A chip specifically designed for network routing"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "An 'ASIC' (Application-Specific Integrated Circuit) is:",
    "options": ["A general-purpose CPU", "An integrated circuit customized for a particular use, rather than intended for general-purpose use", "A type of memory chip", "A standard interface for computer applications"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "An 'FPGA' (Field-Programmable Gate Array) is an integrated circuit that:",
    "options": ["Has a fixed, hardwired logic function", "Can be configured by a customer or a designer after manufacturing, containing an array of programmable logic blocks and a hierarchy of reconfigurable interconnects", "Is programmed only once at the factory", "A type of analog processing chip"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "The term 'microarchitecture' (or computer organization) refers to:",
    "options": ["The instruction set architecture (ISA)", "The specific hardware implementation of an ISA, including details like pipelining, cache organization, execution units, etc. Multiple microarchitectures can implement the same ISA.", "The physical size of the microprocessor", "The architecture of very small computers"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 2
  },
  {
    "question": "A 'page coloring' technique in virtual memory management is used to:",
    "options": ["Color-code pages for easy identification", "Improve cache performance by strategically allocating physical page frames to virtual pages such that cache conflicts are minimized, often by ensuring that pages mapping to the same cache sets are from different parts of the address space if possible.", "Assign different colors to pages based on their access frequency", "A visual debugging tool for page tables"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'Translation Lookaside Buffer (TLB) shootdown' in a multiprocessor system is a process where:",
    "options": ["The TLB hardware is physically shut down", "When a page table entry is modified (e.g., page moved or permissions changed), an inter-processor interrupt (IPI) is sent to other processors to invalidate their corresponding stale TLB entries", "The TLB is flushed due to a security breach", "A specific TLB entry is targeted and removed"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "What is a 'Memory Barrier' or 'Fence' instruction?",
    "options": ["A physical barrier protecting memory chips", "An instruction that enforces an ordering constraint on memory operations; operations issued before the barrier are guaranteed to be performed before operations issued after the barrier, preventing compiler or hardware reordering across the barrier. Crucial for concurrent programming.", "A marker for the end of a memory segment", "A security feature to fence off memory regions"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "The term 'false sharing' in a multiprocessor system with caches occurs when:",
    "options": ["Two processors share a cache line that is invalid", "Two or more processors access different data items that happen to reside in the same cache line. If one processor modifies its data item, the entire cache line may be invalidated in other processors' caches, even if they were accessing unrelated data within that line, causing unnecessary cache coherency traffic and performance degradation.", "Processors incorrectly report sharing data", "Cache lines are shared without proper authorization"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'lock-free' data structure or algorithm is one that:",
    "options": ["Does not use any locks but may use other synchronization primitives", "Guarantees that at least one thread will always make progress in a finite number of steps, even if other threads are stalled or delayed. It avoids traditional locks (mutexes, semaphores) often using atomic operations.", "Is completely free of any synchronization", "Can be accessed without any locking mechanism by the OS"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "A 'wait-free' data structure or algorithm is one that:",
    "options": ["Never requires any thread to wait", "Guarantees that every thread will complete its operation in a finite number of its own steps, regardless of the execution speed or stalling of other threads. This is a stronger guarantee than lock-free.", "Is free of any waiting loops", "Can be accessed without waiting for I/O"],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 3
  },
  {
    "question": "Explain the detailed operation of a modern out-of-order superscalar processor's pipeline, including stages like fetch, decode, rename, dispatch, issue, execute, writeback, and commit. How do reservation stations, reorder buffer (ROB), and common data bus (CDB) facilitate this?",
    "options": [
      "Instructions flow sequentially; ROB reorders them after execution for performance.",
      "Fetch: gets instructions. Decode: determines operations. Rename: assigns temporary registers to avoid WAR/WAW hazards. Dispatch: sends to reservation stations. Issue: instruction with ready operands sent to execution unit. Execute: operation performed. Writeback: result written to CDB, then to ROB & architectural registers if speculative state is correct. Commit: instruction's result made permanent in program order from ROB.",
      "Reservation stations execute instructions; CDB sends them to ROB for renaming.",
      "Superscalar means single instruction stream, out-of-order means multiple data streams."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Describe the MESIF cache coherence protocol. How does the 'Forward' (F) state improve upon MESI, particularly in terms of reducing coherence traffic for read sharing?",
    "options": [
      "MESIF adds a 'Faulty' state to MESI for error detection.",
      "MESIF extends MESI (Modified, Exclusive, Shared, Invalid). The 'Forward' (F) state designates one cache (the forwarder) among multiple sharers to respond to read requests for that block from other caches, instead of main memory. This reduces snoop traffic to memory for frequently read shared blocks, improving scalability.",
      "The 'F' state in MESIF means 'Fast', indicating a high-priority cache line.",
      "MESIF is a write-invalidate protocol, while MESI is write-update."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Explain the concept of a 'branch target buffer' (BTB) and a 'branch history table' (BHT) in dynamic branch prediction. How do they work together, and what is a two-level adaptive predictor?",
    "options": [
      "BTB predicts if branch is taken, BHT stores target address.",
      "BTB: caches target addresses of recently executed branches (indexed by branch instruction address). BHT: stores history of branch outcomes (taken/not-taken) for each branch, often as a saturating counter. Two-level adaptive: uses global history (pattern of recent branches) AND per-branch history to select a BHT entry, improving prediction accuracy by correlating branch behavior.",
      "BHT is a buffer for branch instructions; BTB predicts their outcome.",
      "Two-level adaptive predictors use only global history for all branches."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'Simultaneous Multithreading' (SMT)? How does it differ from traditional chip-level multiprocessing (CMP/multicore), and what hardware resources are typically duplicated versus shared per SMT thread?",
    "options": [
      "SMT means multiple cores share one thread context.",
      "SMT allows a single physical CPU core to execute instructions from multiple hardware thread contexts concurrently by duplicating architectural state (registers, PC) for each thread, but sharing most execution units, caches, and TLBs. CMP/multicore duplicates entire cores. SMT improves core utilization when one thread stalls.",
      "SMT duplicates all core resources for each thread, like CMP.",
      "SMT is a software technique, CMP is hardware."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Describe the challenges and techniques for managing cache coherence in a directory-based coherence protocol for a large-scale NUMA multiprocessor system. How does it differ from snoopy protocols?",
    "options": [
      "Directory-based protocols use a centralized snooping bus.",
      "Snoopy protocols (broadcast-based) don't scale well due to bus contention. Directory-based protocols maintain a distributed directory that tracks sharing status and locations of cache blocks. Coherence messages are point-to-point (unicast/multicast) via the interconnection network, guided by the directory. Challenges: directory storage overhead, latency of directory lookups and message passing, maintaining directory consistency.",
      "Snoopy protocols are more scalable than directory-based for NUMA.",
      "Directory-based protocols require all caches to snoop all memory accesses."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Explain the concept of 'Transactional Memory' (TM), both hardware (HTM) and software (STM). What problem does it aim to solve, and what are its key challenges?",
    "options": [
      "TM is a memory type for financial transactions only.",
      "TM aims to simplify concurrent programming by allowing programmers to define atomic blocks of code (transactions) that appear to execute in isolation. If a conflict occurs (e.g., data race), the transaction is typically aborted and retried. HTM uses hardware support. STM implements it in software. Challenges: performance overhead, contention management, composability, handling irrevocable operations (I/O).",
      "STM is always faster than HTM due to software flexibility.",
      "TM guarantees all transactions will eventually commit without retries."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'power gating' and 'clock gating' in low-power CPU design? How do they contribute to reducing static and dynamic power consumption respectively?",
    "options": [
      "Power gating increases power, clock gating increases clock speed.",
      "Clock gating: disables clock signal to idle functional units, reducing dynamic power (P ~ CV²f) by eliminating switching activity. Power gating: cuts off power supply to idle blocks/cores, significantly reducing static (leakage) power. Both are crucial for managing power in modern CPUs, but power gating has higher wakeup latency.",
      "Clock gating reduces static power; power gating reduces dynamic power.",
      "Both techniques only reduce dynamic power consumption."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Describe the working principle of a 'prefetcher' in a modern CPU. Discuss different types of prefetchers (e.g., stream prefetcher, stride prefetcher) and the challenges in designing effective prefetchers.",
    "options": [
      "Prefetchers only fetch instructions, not data.",
      "Prefetchers speculatively fetch data/instructions into cache before they are explicitly requested, aiming to hide memory latency. Stream prefetchers detect sequential access patterns. Stride prefetchers detect access with fixed strides. Challenges: accuracy (avoiding cache pollution with useless data), timeliness (fetching just before needed), coverage (identifying complex patterns), hardware cost.",
      "Stream prefetchers are for video streaming; stride prefetchers for striding gaits.",
      "Prefetchers always improve performance without any downsides."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'Dennard Scaling', and why has its breakdown led to the 'power wall' and the rise of multicore processors?",
    "options": [
      "Dennard scaling states power increases with transistor size.",
      "Dennard scaling (historically) observed that as transistor dimensions shrink, power density remains constant (voltage/current scale down proportionally), allowing increased clock speeds and transistor counts without excessive power. Its breakdown (leakage power didn't scale well, voltage scaling hit limits) led to the power wall, where increasing clock speed became too power-hungry. This shifted focus to multicore designs for performance gains through parallelism.",
      "The power wall led to Dennard scaling for multicore CPUs.",
      "Dennard scaling is about increasing cache size, not related to power."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Explain the architecture and benefits of a 'Network-on-Chip' (NoC) compared to traditional bus-based interconnects for multicore SoCs.",
    "options": [
      "NoC uses a single shared bus for all cores, like traditional systems.",
      "A NoC uses packet-switched networking principles (routers, links) to connect components (cores, caches, memory controllers, IP blocks) on a chip. Benefits over shared buses: better scalability for many cores (avoids bus contention), higher bandwidth, modularity, potential for QoS. Challenges: latency, power consumption of routers/links, design complexity.",
      "Traditional buses are more scalable than NoCs for large SoCs.",
      "NoC is a software framework for on-chip communication."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'Heterogeneous Computing' (e.g., CPU + GPU + DSPs)? What are the architectural and programming challenges associated with it?",
    "options": [
      "Using only one type of processor, but many of them.",
      "Heterogeneous computing uses multiple types of specialized processing units (e.g., CPUs for general tasks, GPUs for parallel computation, DSPs for signal processing) in a single system to optimize for different workloads. Challenges: data movement between different memory spaces, programming model complexity (different ISAs, APIs), task scheduling and load balancing across diverse units, coherence between disparate caches.",
      "It means all processors are identical but run different operating systems.",
      "Heterogeneous computing simplifies programming by using a single ISA."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Describe how a Translation Lookaside Buffer (TLB) works, including handling of TLB hits and misses, and the role of page table walkers. What are superpages/hugepages in this context?",
    "options": [
      "TLB stores entire page tables; page table walkers look for free pages.",
      "TLB is a hardware cache for virtual-to-physical address translations (page table entries). On a TLB hit, physical address is quickly available. On a miss, a hardware (or software) page table walker traverses the page table in memory to find the PTE, which is then loaded into the TLB. Superpages/hugepages use larger page sizes (e.g., 2MB, 1GB), reducing TLB entries needed for large memory regions, thus improving TLB hit rates and reducing page walk overhead.",
      "TLB is a buffer for disk I/O; superpages are very large disk blocks.",
      "Page table walkers update the TLB on every instruction fetch."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'Row Hammer' vulnerability in DRAM, and what are some mitigation techniques?",
    "options": [
      "A physical attack using a hammer on DRAM rows.",
      "Row Hammer is a hardware vulnerability where repeatedly accessing (hammering) a row of DRAM cells can cause bit flips in adjacent rows due to electrical interference, even without directly accessing those adjacent rows. Mitigations: increased refresh rates, target row refresh (TRR - refreshing victim rows), error correcting codes (ECC) that can correct more bits, hardware design changes.",
      "It's a software bug that hammers the CPU with requests.",
      "Row Hammer is mitigated by using SRAM instead of DRAM."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Explain the concept of 'memory consistency models' (e.g., sequential consistency, relaxed consistency). Why are they important in multiprocessor systems?",
    "options": [
      "Models for ensuring RAM modules are physically consistent.",
      "Memory consistency models define the rules for the apparent order in which memory operations (reads and writes) by different processors become visible to each other. Sequential consistency: all operations appear to execute in some global sequential order consistent with program order on each processor. Relaxed models allow more reordering for performance but require explicit synchronization (fences, barriers) for correctness. Important for correct concurrent programming.",
      "Sequential consistency is the fastest model due to strict ordering.",
      "Relaxed consistency means memory errors are tolerated."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What are 'memory barriers' (or fences), and why are they necessary in systems with relaxed memory consistency models or when interacting with I/O devices?",
    "options": [
      "Physical barriers in RAM to prevent data corruption.",
      "Memory barriers are instructions that enforce ordering constraints on memory operations. They prevent the compiler and hardware from reordering memory accesses across the barrier. Necessary with relaxed models to ensure writes by one processor become visible to others in a specific order, or to ensure writes to device registers occur before/after other operations when interacting with memory-mapped I/O.",
      "Memory barriers increase memory access speed by removing ordering.",
      "They are used to fence off unused memory regions."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Describe the architecture of a typical GPU (Graphics Processing Unit) and explain why it is well-suited for massively parallel computations (GPGPU).",
    "options": [
      "GPUs have a few very powerful cores optimized for serial tasks.",
      "GPUs have a highly parallel architecture with many (hundreds/thousands) smaller, simpler cores (Streaming Multiprocessors - SMs, each with many CUDA cores/ALUs). They are designed for high throughput on data-parallel tasks by executing the same instruction (or kernel) on many data elements simultaneously (SIMT - Single Instruction, Multiple Threads). They have high memory bandwidth and specialized memory hierarchies.",
      "GPUs use RISC architecture, CPUs use CISC, making GPUs parallel.",
      "GPUs are primarily for graphics; their architecture is not suitable for GPGPU."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is a 'race condition' in concurrent programming, and how can architectural features or synchronization primitives help prevent it?",
    "options": [
      "When two CPUs race to finish a computation.",
      "A race condition occurs when the outcome of a computation depends on the unpredictable timing or interleaving of operations by multiple threads/processes accessing shared mutable state. Architectural features: atomic instructions (e.g., compare-and-swap, fetch-and-add). Synchronization primitives: mutexes, semaphores, condition variables, memory barriers, which ensure orderly access to shared resources.",
      "A hardware condition where signals race on a bus.",
      "Race conditions are only a software issue, not related to architecture."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Explain the difference between 'speculative execution' and 'out-of-order execution'. How do they relate?",
    "options": [
      "They are synonyms for the same technique.",
      "Out-of-order execution allows instructions to execute in an order different from program order if data dependencies allow, to improve utilization. Speculative execution takes this further by executing instructions *before* it's certain they are on the correct path (e.g., after a predicted branch). If speculation is wrong, results are discarded. Out-of-order execution often enables more opportunities for speculation.",
      "Out-of-order executes committed instructions; speculative executes predicted instructions.",
      "Speculative execution is about data, out-of-order is about control flow."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What are 'side-channel attacks' (e.g., Spectre, Meltdown) in the context of modern processor architectures, and what makes them particularly challenging to mitigate?",
    "options": [
      "Attacks through physical side channels like power cables.",
      "Side-channel attacks exploit information leaked from a system's physical implementation, rather than direct software vulnerabilities. Examples: timing information, power consumption, electromagnetic leaks. Spectre/Meltdown exploited microarchitectural side effects of speculative execution and out-of-order execution to leak data across security boundaries. Challenging because they exploit fundamental performance optimizations, and mitigations can incur performance costs or require hardware changes.",
      "Attacks that use social engineering on the side.",
      "Side-channel attacks target only cache memory, not other CPU parts."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is the 'Write Invalidate' vs 'Write Update' strategy in cache coherence protocols?",
    "options": [
      "Write Invalidate updates other caches; Write Update invalidates them.",
      "Write Invalidate: When a processor writes to a shared cache block, it invalidates copies of that block in other caches. Subsequent reads by other processors will miss and fetch the new version. Write Update: When a processor writes to a shared block, it broadcasts the updated data to all other caches holding a copy, updating their versions. Write Invalidate is more common due to lower bandwidth usage.",
      "Write Invalidate is for L1, Write Update for L2 cache.",
      "Both strategies are identical in terms of bandwidth usage."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Describe the concept of 'false sharing' in a multiprocessor system with coherent caches. Why does it occur and how can it be mitigated?",
    "options": [
      "When processors share data that is incorrectly marked as false.",
      "False sharing occurs when two or more processors access different, independent data items that happen to reside in the same cache line. If one processor modifies its data item, the entire cache line (containing both used and unused data for other processors) may be invalidated or updated in other caches due to coherence protocols, even though the other processors were not interested in the modified data. Mitigation: padding data structures to align critical shared variables to separate cache lines.",
      "It's when caches falsely report sharing data when they are not.",
      "False sharing is a software bug, not a hardware/cache issue."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is a 'hypervisor' and what are the differences between Type 1 (bare-metal) and Type 2 (hosted) hypervisors?",
    "options": [
      "A hypervisor supervises user application performance.",
      "A hypervisor (or Virtual Machine Monitor - VMM) is software, firmware, or hardware that creates and runs virtual machines. Type 1 (bare-metal): runs directly on the host's hardware to control the hardware and manage guest OSs (e.g., VMware ESXi, Xen, Hyper-V). Type 2 (hosted): runs on a conventional operating system just like other computer programs (e.g., VMware Workstation, VirtualBox).",
      "Type 1 runs on an OS, Type 2 directly on hardware.",
      "Type 2 hypervisors are more performant than Type 1."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Explain 'hardware support for virtualization' (e.g., Intel VT-x, AMD-V). What problems did it solve for x86 virtualization?",
    "options": [
      "It allows virtual machines to use dedicated hardware components.",
      "Early x86 virtualization faced challenges because some sensitive instructions didn't trap to the hypervisor when run in user mode, requiring complex binary translation. Hardware support (VT-x/AMD-V) introduced new CPU modes and instructions (e.g., VMX root/non-root operation, EPT/NPT for memory virtualization) that allow guest OSs to run more directly on hardware while still giving control to the hypervisor for privileged operations, improving performance and simplifying hypervisor design.",
      "It virtualizes hardware drivers for better compatibility.",
      "It's primarily for running x86 applications on non-x86 hardware."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'Single Root I/O Virtualization' (SR-IOV)? How does it improve I/O performance for virtual machines?",
    "options": [
      "A way to virtualize only the root I/O hub.",
      "SR-IOV is a hardware specification that allows a single PCIe device (e.g., network card, GPU) to appear as multiple separate physical PCIe devices (Virtual Functions - VFs) to virtual machines. Each VM can be directly assigned one or more VFs, bypassing the hypervisor's I/O virtualization layer for those devices, leading to lower latency and higher throughput for I/O operations.",
      "It allows multiple VMs to share a single virtual I/O device managed by the hypervisor.",
      "SR-IOV virtualizes the system's root filesystem for I/O."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Discuss the different levels of RAID (0, 1, 5, 6, 10) in terms of performance, redundancy, and capacity utilization.",
    "options": [
      "RAID 0 has best redundancy; RAID 6 best performance.",
      "RAID 0 (Striping): Best performance (read/write), no redundancy, full capacity. RAID 1 (Mirroring): Good read perf, full redundancy (1 disk fail), 50% capacity. RAID 5 (Distributed Parity): Good read perf, decent write, 1 disk redundancy, (N-1)/N capacity. RAID 6 (Dual Parity): Good read, slower write than RAID 5, 2 disk redundancy, (N-2)/N capacity. RAID 10 (Stripe of Mirrors): Good read/write, 1 disk per mirror fail, 50% capacity.",
      "RAID 5 uses dedicated parity disk; RAID 10 has no redundancy.",
      "Capacity utilization is highest for RAID 1 and lowest for RAID 0."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'error detection and correction' in memory systems (e.g., ECC RAM)? How do Hamming codes work conceptually for single-bit error correction and double-bit error detection (SEC-DED)?",
    "options": [
      "ECC RAM detects errors but cannot correct them.",
      "ECC RAM uses extra parity bits to detect and correct single-bit errors and detect double-bit errors. Hamming codes add parity bits calculated over specific subsets of data bits. The pattern of parity check failures (syndrome) indicates the position of a single-bit error, allowing it to be corrected by flipping that bit. More complex patterns indicate multi-bit errors (some detectable).",
      "Hamming codes can correct any number of bit errors.",
      "ECC RAM works by duplicating all data for error checking."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Explain the concept of instruction encoding in an ISA. Discuss trade-offs between fixed-length and variable-length instruction encodings.",
    "options": [
      "Encoding is about encrypting instructions for security.",
      "Instruction encoding defines how instructions (opcodes, operands, addressing modes) are represented in binary. Fixed-length (common in RISC): simpler decoding, easier pipelining. Cons: potentially wasted space for simple instructions or limited immediate values. Variable-length (common in CISC): better code density (smaller programs), more addressing modes/operand types. Cons: complex decoding, harder pipelining.",
      "Fixed-length is always more code-dense than variable-length.",
      "Variable-length encoding simplifies CPU decoding hardware."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'microcode' (or microprogramming) and how is it used in some CISC processor control units?",
    "options": [
      "Very small C code programs for embedded systems.",
      "Microcode is a layer of hardware-level instructions (microinstructions) stored in a special control memory (control store) that implement the higher-level machine instructions of a CISC processor. The control unit fetches and executes sequences of microinstructions to perform the steps required by each machine instruction. Allows for complex instructions and easier ISA modification/bug fixing compared to hardwired control.",
      "Microcode is used by RISC processors to simplify instructions.",
      "It's a form of source code that is smaller than assembly."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Discuss the architectural features and trade-offs of VLIW (Very Long Instruction Word) processors compared to superscalar processors.",
    "options": [
      "VLIW uses runtime scheduling, superscalar uses compile-time.",
      "VLIW: Compiler packs multiple independent operations into a single long instruction word, hardware is simpler as it executes these in parallel without complex dependency checking. Pros: simpler hardware, potentially lower power. Cons: compiler complexity, performance highly dependent on compiler's ability to find ILP, code bloat if parallelism isn't found (NOPs). Superscalar: Hardware dynamically finds and issues multiple instructions. Pros: more resilient to code variations. Cons: complex hardware.",
      "Superscalar always has better performance than VLIW.",
      "VLIW instructions are variable length, superscalar fixed."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What are 'SIMD' (Single Instruction, Multiple Data) extensions (e.g., MMX, SSE, AVX, NEON) in modern CPUs? How do they improve performance for certain workloads?",
    "options": [
      "SIMD executes multiple different instructions on a single data element.",
      "SIMD extensions provide instructions that perform the same operation on multiple data elements (packed into wide registers) simultaneously. This data-level parallelism significantly speeds up workloads with regular, repetitive operations on large datasets, such as multimedia processing (audio, video, graphics), scientific computing, and cryptography.",
      "SIMD is a way to run multiple threads on a single instruction.",
      "They are instruction sets for simple microcontrollers only."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Explain the concept of 'Amdahl's Law' and its implications for parallel computing and system optimization.",
    "options": [
      "Amdahl's Law states that speedup is proportional to number of cores.",
      "Amdahl's Law gives the theoretical speedup in latency of the execution of a task at fixed workload that can be expected of a system whose resources are improved. It states that the speedup is limited by the fraction of the task that is inherently sequential (cannot be parallelized). Implication: optimizing the sequential part or increasing parallelism of the parallelizable part yields diminishing returns if a significant sequential portion remains.",
      "Amdahl's Law only applies to single-core performance improvements.",
      "It calculates the maximum number of parallel tasks a system can handle."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'Gustafson's Law' and how does it offer a different perspective on scalability compared to Amdahl's Law?",
    "options": [
      "Gustafson's Law focuses on fixed problem size speedup.",
      "Gustafson's Law argues that with more computing resources (e.g., processors), larger problems can be solved in the same amount of time (scaled speedup). It assumes the parallelizable part of a task scales with the number of processors, while the sequential part remains fixed or grows slowly. It offers a more optimistic view for massively parallel systems working on large problems, contrasting with Amdahl's fixed-workload perspective.",
      "Gustafson's Law states that sequential parts always limit speedup.",
      "It's an alternative to Moore's Law for transistor scaling."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Describe the challenges of 'Memory Wall' in computer architecture.",
    "options": [
      "A physical wall built around memory chips for protection.",
      "The Memory Wall refers to the growing disparity between processor speed and memory access speed (latency and bandwidth). While CPU speeds have increased rapidly (historically), memory speeds have improved at a slower pace. This creates a bottleneck where the CPU often waits for data from memory, limiting overall system performance. Caches and prefetching help mitigate this but don't eliminate it.",
      "It's a limit on the maximum amount of RAM a system can have.",
      "A software firewall protecting memory access."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What are 'systolic arrays' and for what types of computations are they particularly well-suited?",
    "options": [
      "Arrays that measure blood pressure in medical devices.",
      "A systolic array is a network of simple processing elements (PEs) arranged in a regular grid-like structure. Data flows rhythmically across the array between neighboring PEs, often in multiple directions, with each PE performing a small computation on the data as it passes. They are well-suited for highly regular, compute-intensive tasks like matrix multiplication, convolution (used in DNNs), and signal processing, offering high parallelism and data reuse.",
      "Arrays that store systolic heartbeats.",
      "A software array data structure for system-level operations."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "Explain the concept of 'dataflow architecture'. How does it differ from traditional Von Neumann control-flow architectures?",
    "options": [
      "Dataflow means data flows sequentially through Von Neumann stages.",
      "In a dataflow architecture, program execution is driven by the availability of data (operands) rather than a program counter dictating a sequence of instructions. An instruction (or node in a dataflow graph) executes only when all its required inputs are available. This inherently exposes parallelism. Von Neumann is control-flow driven, with explicit instruction sequencing.",
      "Dataflow architectures use a program counter to manage data flow.",
      "Von Neumann is more parallel than dataflow due to pipelining."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  },
  {
    "question": "What is 'near-data processing' or 'processing-in-memory' (PIM)? What are its potential benefits?",
    "options": [
      "Processing data that is physically near the CPU cache.",
      "PIM involves performing computation directly within or very close to memory units (e.g., on DRAM chips or in 3D-stacked memory), rather than moving large amounts of data to a separate CPU. Potential benefits: significantly reduced data movement overhead (energy, latency), increased memory bandwidth utilization, and potentially higher overall system performance for data-intensive workloads.",
      "Storing processing units inside data structures.",
      "Processing data only after it has been moved near the CPU."
    ],
    "answer": 1,
    "category": "Computer Architecture",
    "difficulty": 4
  }
]